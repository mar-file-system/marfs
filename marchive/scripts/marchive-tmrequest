#!/usr/bin/env python3.12
# coding=utf-8

"""
Tape Manager Requester

@author David Sherrill <dsherril@lanl.gov>
"""
# Splits output generated from a MarFS utility that produces object data
# lists so that it can be digested by the marchive Tape Manager. The list
# output from must have object and location information in it. Lines
# in the output should have the following format (including "[]"):
#     [object id][stripe][pod][cap][scatter]
#
# This script can read from a variety of sources, including running
# commands that generate object data in the format specified above.
# The following is an example of how to specify a generating command:
#     marchive-tmrequest --verbose -j xjunkx -X flush -- cat testfile
#
# The following options are accepted by this script:
#    usage: marchive-tmrequest [-h] [-c TMCONFIG] [-d] [-E ENVFILE] [-f INFILE] [-j JOBTAG] [-L LOGDIR] [-q]
#                              [-S SYSLOGDEV] [--verbose] [-X]
#                              task [gencmd ...]
#
#    marchive-tmrequest -- Options
#
#    positional arguments:
#      task                  The operation to configure the mustang for. (values: read,delete,flush,push)
#      gencmd                A command that generates approriate object output that can be formatted in request
#                            for the Tape Manager. This command/utility should be able to generate output to
#                            STDOUT.
#
#    options:
#      -h, --help            show this help message and exit
#      -c TMCONFIG, --tmconfig TMCONFIG
#                            File containing the Marchive Tape Manager configuration (default: Value of
#                            MARCHIVE_TMCONFIG_PATH environment variable)
#      -d, --debug           Prints the debugging statements, unless "-q" is specified (default: off)
#      -E ENVFILE, --envfile ENVFILE
#                            File containing the Marchive environment variables used by this script (default:
#                            <Installed Marchive ENV file>)
#      -f INFILE, --infile INFILE
#                            File containing object (with location) output from a utility that generates the
#                            required request information. This option is ignored if a command is given
#                            (default: Reads from STDIN, unless "-X" is specified)
#      -j JOBTAG, --jobtag JOBTAG
#                            Specifies a string (with no spaces) to include in the name of the generated job
#                            files. This option is required if -X is set and there is no object output to
#                            process.
#      -L LOGDIR, --logdir LOGDIR
#                            Directory to write the log file. If this option is not specified, and
#                            MARCHIVE_LOGDIR_PATH is not set, then no log file is generated (default: Value of
#                            MARCHIVE_LOGDIR_PATH environment variable)
#      -q, --quiet           Turns off all console output (default: off)
#      -S SYSLOGDEV, --syslog SYSLOGDEV
#                            Device used to write log messages to SYSLOG (default: /dev/log)
#      --verbose             Turns on additional console output (default: off)
#      -X, --cleanup         Removes files from the Tape Manager's output directory (default: off)
#
# A good pylint command for this file:
#    pylint --max-line-length 175 -d C0103 -d C0116 -d R1732 marchive-tmrequest

import argparse
from datetime import datetime
import io
import logging
import logging.handlers
import os
from pathlib import Path
import re
import subprocess
import sys
import time
import tomllib

DEFAULT_ENVFILE = "marchive.env"                                      # File containing the running environment for this script
TMCONFIG = "MARCHIVE_TMCONFIG_PATH"                                   # Name of the environment variable to hold the Tape Manager configuration file
LOGDIR = "MARCHIVE_LOGDIR_PATH"                                       # Name of the environment variable to hold a log directory path

REGX_COMMENT_LINE = re.compile(r"[#].*|^\s*$")                        # Compiled Regular expression to match a comment line or empty line
REGX_ENV_LINE = re.compile(r"(export\s+)*([A-Z0-9_]+)\s*=\s*(.+)")    # Compiled Regular expression to match an environment variable line
                                                                      # Compiled Regular expression used to parse object output
REGX_OBJECT_LINE = re.compile(r"\s*\[(.+)\]\s*\[([0-9]+)\]\s*\[([0-9]+)\]\s*\[([0-9]+)\]\s*\[([0-9]+)\]\s*")

# Key strings to use for direcory/file maps
FILEKEY = "__file"
CONTENTKEY = "__contents"
GENKEY = "gen"
INPUTKEY = "input"
SUCCESSKEY = "success"
FAILKEY = "fail"

logger = logging.getLogger('TMREQUEST_LOGGER')                        # global logger for the script - set up in main()

#======================================================================
# Processes a line from an env file. Comment lines are simply ignored.
# Since this routine is called prior to logging being initialized,
# all messages are written to stderr.
#
#  Args:
#       inline (str): the line to process
#       verbose (bool): if set, prints a line for each variable
#                       assigned by this routine
#======================================================================
def process_env_line(inline,verbose):
    # Ignore comment lines
    if REGX_COMMENT_LINE.match(inline) is not None:
        return

    inline = inline.strip()                                           # strip off new line...
    # Parse the line
    linedata = REGX_ENV_LINE.fullmatch(inline)
    if linedata is None:
        sys.stderr.write(f"ERROR: Invalid environment line: {inline}\n")
        return
    name = linedata.group(2)                                          # group 1 is the word "export", if it given on the line
    rawvalue = str(linedata.group(3)).strip('\'"')                    # removes any enclosing quotes in value

    if name not in os.environ:                                        # assign only the missing variables ...
        if name.endswith('_PATH'):
            value = str(Path(rawvalue).resolve())                     # makes sure all _PATH variables have full path values
        else:
            value = rawvalue
        os.environ[name] = value
        if verbose:
            print(f"DEBUG: {name} = [{value}]")

#======================================================================
# Constructs the config directory, based on the absolute path of the
# executable script. If the script is in a "bin" directory, then it is
# assumed that script is in an installed tree. This implies that
# the config dirctory would be a sibling directory called "etc".
# If the script is not in a "bin" directory, then we assume that the
# config directory is the same directory where the script is located.
# (This would a testing on non-installed configuration for the files.)
#
# This hack means that the location of the config directory can be
# determined programatically, and not rely on a install macro to
# determine it. Garrett Ransom suggested this hack.
#======================================================================
def gen_config_path():
    execdir = Path(__file__).absolute().parent

    if str(execdir).endswith('/bin'):
        configpath = f"{execdir.parent}/etc"
    else:
        configpath = str(execdir)

    return configpath

#======================================================================
# Reads the given envronment file, and sets the scripts running
# environment to the values contained there in. Note that it tests to
# see if an evironment variable already has a value before setting it.
# That means that environment values set prior to this script's
# invocation have precidence.
#
# This routine is typically called before logging is set up. As such.
# it write all messages to stderr/stdout. In particular, if the specified
# envronment file does not exist, then a message saying that is written
# to stderr, and this routine exits.
#
#  Args:
#       marchenv (str): the path to the Marchive environment file.
#                       Typically this is a full path (but that is
#                       not required).
#       verbose (bool): if set, prints a line for each variable
#                       assigned by this routine
#======================================================================
def setenv_marchive(marchenv, verbose):
    envfile = Path(marchenv).resolve()                                # path to the specified marchive env file

    if not envfile.exists():
        sys.stderr.write(f"The environment file {envfile} is not found.\n"+
            "WARNING: Only the currently set envronment will be used by this "+
            "script.\n")
        return

    try:
        with envfile.open(mode='r', encoding="utf-8") as envfh:
            for envline in envfh:
                process_env_line(envline, verbose)
    except OSError as e:
        sys.stderr.write(f"Failed to read {envfile}: {e}\nWARNING: Only the "+
            "currently set envronment will be used by this script.\n") 

#======================================================================
# Sets up the logging for this script, based on the commandline
# options, as well as the environment.
#
#  Args:
#       opts (namespace): a List of arguments and values returned by
#                         ArgumentParser.parse_args()
#       pname (str): the name of process
#======================================================================
def setup_log(opts, pname):
    logdir = None                                                     # log directory starts with a NULL value

    logger.setLevel(logging.DEBUG)
    if opts.logdir:                                                   # handle the logdir option
        logdir = Path(opts.logdir[0])
    elif os.getenv(LOGDIR):
        logdir = Path(str(os.getenv(LOGDIR)))
                                                                      # always write to syslog
    slhandle = logging.handlers.SysLogHandler(address = opts.syslogdev[0])
    slhandle.setFormatter(logging.Formatter('%(filename)s[%(process)d]: %(message)s'))
    if opts.debug:
        slhandle.setLevel(logging.DEBUG)
    else:
        slhandle.setLevel(logging.INFO)
    logger.addHandler(slhandle)

    if logdir:                                                        # writes to a log file, if a directory is specified
        flhandle = logging.FileHandler(f"{logdir.resolve()}/{pname}.log")
        flhandle.setFormatter(logging.Formatter('%(asctime)s.%(msecs)d %(levelname)s: %(message)s',
            datefmt='%d %b %Y %T'))
        if opts.debug:
            flhandle.setLevel(logging.DEBUG)
        else:
            flhandle.setLevel(logging.INFO)
        logger.addHandler(flhandle)

    if not opts.quiet:                                                # Writes to the console, if not turned off
        clhandle = logging.StreamHandler()                            # writes to STDERR (by default)
        clhandle.setFormatter(logging.Formatter('%(levelname)s: %(message)s'))
        if opts.debug:
            clhandle.setLevel(logging.DEBUG)
        elif opts.verbose:
            clhandle.setLevel(logging.INFO)
        else:
            clhandle.setLevel(logging.WARNING)
        logger.addHandler(clhandle)

#======================================================================
# Parse a string of the format "H:M:S", and returns the number of
# seconds specified.
#
#  Args:
#       tstr (datetime.time): a string of the form "00:00:00"
#
#  Returns:
#       int: the number of seconds represented by the string. If
#            the string is not valid, then a ValueError will be
#            thrown.
#======================================================================
def get_timeout(tstr):
    return tstr.hour*3600+tstr.minute*60+tstr.second

#======================================================================
# Sets up the Tape Manager string maps needed by process_object_line()
# in order to form directory and file names
#
#  Args:
#       cfg (dict): a TOML configuration dictionary, containing the
#                   Tape Manager directory strings
#
#  Returns:
#       dict: a dictionary indexed by the following TM states -
#             (generating,input,output/success,output/failure)
#======================================================================
def setup_dirmaps(cfg):
    dirmap = {}                                                       # map to return

    tmroot = cfg['options']['root']

    dirmap[FILEKEY] = cfg['options']['task_file_path']
    dirmap[CONTENTKEY] = cfg['options']['task_file_content']
    dirmap[GENKEY] = f"{tmroot}/{cfg['options']['generating_subdir']}"
    dirmap[INPUTKEY] = f"{tmroot}/{cfg['options']['input_subdir']}"
    dirmap[SUCCESSKEY] = f"{tmroot}/{cfg['options']['output_success_subdir']}"
    dirmap[FAILKEY] = f"{tmroot}/{cfg['options']['output_failure_subdir']}"

    return dirmap

#======================================================================
# Writes the file (and contents) to the generating portion of the Tape
# Manager's tree. If this is a newly created file in the TM tree, then
# it is also added to the file table, along with all TM paths necessary
# to have this script track its progress.
#
#  Args:
#       jobfile (str): contains the partial path of the file that needs
#                      to be written to
#       content (str): the line to be written into the file
#       dirmaps (dict): holds string maps and directory roots, used to
#                       form various paths, based on what is needed
#       filetab (dict): a dictionary to store all files generated by
#                       processing lines
#======================================================================
def write_genfile(jobfile, content, dirmaps, filetab):

    if not jobfile in filetab:
        fentry = {}                                                   # an entry into the file table

        fentry[GENKEY] = Path(f"{dirmaps[GENKEY]}/{jobfile}")
        fentry[INPUTKEY] = f"{dirmaps[INPUTKEY]}/{jobfile}"
        fentry[SUCCESSKEY] = Path(f"{dirmaps[SUCCESSKEY]}/{jobfile}")
        fentry[FAILKEY] = Path(f"{dirmaps[FAILKEY]}/{jobfile}")

        gendir = Path(fentry[GENKEY].parent)

        try:
            if not gendir.exists():
                gendir.mkdir(parents=True)
        except OSError as e:
            logger.error("Failed to create directory %s: %s", gendir, e)
            logger.error("Did not add [%s] to file table.", jobfile)
            return
        try:
            fentry[GENKEY].touch(exist_ok=False)                      # simulate create exclusive...
        except OSError as e:
            logger.error("Failed to create file %s: %s", fentry[GENKEY], e)
            logger.error("Did not add [%s] to file table.", jobfile)
            return

        filetab[jobfile] = fentry

    # Write the content to the job file
    genfile = filetab[jobfile][GENKEY]

    logger.debug("Writing [%s] to %s", content, genfile)
    try:
        with genfile.open(mode='a', encoding="utf-8") as genfh:
            genfh.write(content+"\n")
    except OSError as e:
        logger.error("Failed to write content to %s: %s",
            genfile, e)

    return

#======================================================================
# Processes a line from an object list output file or stream. Comment
# lines are simply ignored.
#
#  Args:
#       inline (str): the line to process
#       tmtask (str): indicates the task the Task Manager should do
#                     with the data from the lines
#       job (str): Name if the current job processing the line. Used
#                  to create the output file name (jobfile)
#       dirmaps (dict): holds string maps and directory roots, used to
#                       form various paths, based on what is needed
#       filetab (dict): a dictionary to store all files generated by
#                       processing lines
#======================================================================
def process_object_line(inline, tmtask, job, dirmaps, filetab):

    jobfile = f"{job}.req"                                            # formed, base on the name of running job

    # Ignore comment lines
    if REGX_COMMENT_LINE.match(inline) is not None:
        return

    inline = inline.strip()                                           # strip off new line...
    # Parse the line
    linedata = REGX_OBJECT_LINE.fullmatch(inline)
    if linedata is None:
        logger.error("Invalid output line: %s", inline)
        return
    objid = linedata.group(1)
    maxstripe = int(linedata.group(2))
    pod = linedata.group(3)
    cap = linedata.group(4)
    scatter = linedata.group(5)

    # Now add object to appropriate files in the Tape Manager tree/file table
    for b in range(0,maxstripe):
        linedict = {'task':tmtask, 'pod':pod, 'block':b, 'cap':cap,
                    'scatter':scatter, 'object':objid, '_':jobfile}
        tmfile = dirmaps[FILEKEY].format_map(linedict)
        tmline = dirmaps[CONTENTKEY].format_map(linedict)
        write_genfile(tmfile, tmline, dirmaps, filetab)

    return

#======================================================================
# Submits a generated job file to the tape manger. This is done by
# moving (i.e. renameing) the generated job file into the tape
# manager's input tree. All information needed to perform this
# operation is contanted in the table entry.
#
#  Args:
#       tabentry (dict): an entry from the job file table
#
#  Returns:
#       bool: True, if the files was successfully renamed to the
#             Tape Manager input tree. False otherwise
#======================================================================
def submit_jobfile(tabentry):
    inputfile = Path(tabentry[INPUTKEY])
    inputdir = Path(inputfile.parent)

    try:
        if not inputdir.exists():
            inputdir.mkdir(parents=True)
    except OSError as e:
        logger.error("Failed to create directory %s: %s",
            inputdir, e)
        return False

    genfile = tabentry[GENKEY]
    try:
        genfile.replace(inputfile)
    except OSError as e:
        logger.error("Failed to replace %s: %s",
            inputfile, e)
        return False

    return True

#======================================================================
# MAIN for marchsplitter script
#======================================================================
if __name__=="__main__":
    errorhappened = False                                             # a flag to indicate if there were errors during processing
    config = {}                                                       # a TOML configuration object
    ftab = {}                                                         # a table to hold all files created/managed by this script
    cleanupfiles = []                                                 # a list of files to clean up. Used if "-X" specified
    clntname = os.path.basename(sys.argv[0])                          # name of script
    procname = f"{clntname}_{os.getpid()}"                            # name of the process to use/log

    ihandle = None                                                    # input stream handle to read lines from (could be either file or socket)
    isrcname = ''                                                     # name of the input source in string form
    iproc = None                                                      # a subprocess object for a given generating command
    looptime = 60                                                     # seconds to wait in a loop - typically based on the task
    maxjoblines = 100000                                              # maximum lines processed for a job - need to make this configurable - cds 8/2025
    cmdline = argparse.ArgumentParser(prog=clntname,
        description='%(prog)s --  Options')

    # Set up agruments and parse them
    cmdline.add_argument('task',
        help='The operation to configure the mustang for. '+
            '(values: read,delete,flush,push)')
    cmdline.add_argument('gencmd', nargs='*',
        help='A command that generates approriate object output that can be '+
            'formatted in request for the Tape Manager. This command/utility '+
            'should be able to generate output to STDOUT.')
    cmdline.add_argument('-c', '--tmconfig', dest='tmconfig', nargs=1, default='',
        help='File containing the Marchive Tape Manager configuration '+
            f'(default: Value of {TMCONFIG} environment variable)')
    cmdline.add_argument('-d', '--debug', dest='debug', default=False, action='store_true',
        help='Prints the debugging statements, unless "-q" is specified '+
            '(default: off)')
    cmdline.add_argument('-E', '--envfile', dest='envfile', nargs=1, default=None,
        help='File containing the Marchive environment variables used by this script '+
            f'(default: <installdir>/etc/{DEFAULT_ENVFILE})')
    cmdline.add_argument('-f', '--infile', dest='infile', nargs=1, default=['/dev/stdin'],
        help='File containing object (with location) output from a utility that '+
            'generates the required request information. This option is ignored '+
            'if a command is given (default: Reads from STDIN, unless "-X" is '+
            'specified)')
    cmdline.add_argument('-j', '--jobtag', dest='jobtag', nargs=1, default='',
        help='Specifies a string (with no spaces) to include in the name of the '+
            'generated job files. This option is required if -X is set and there '+
            'is no object output to process.')
    cmdline.add_argument('-L', '--logdir', dest='logdir', nargs=1, default='',
        help='Directory to write the log file. If this option is not specified, '+
            f'and {LOGDIR} is not set, then no log file is generated '+
            f'(default: Value of {LOGDIR} environment variable)')
    cmdline.add_argument('-q', '--quiet', dest='quiet', default=False, action='store_true',
        help='Turns off all console output (default: off)')
    cmdline.add_argument('-S', '--syslog', dest='syslogdev', nargs=1, default=['/dev/log'],
        help='Device used to write log messages to SYSLOG '+
            '(default: /dev/log)')
    cmdline.add_argument('--verbose', dest='verbose', default=False, action='store_true',
        help='Turns on additional console output (default: off)')
    cmdline.add_argument('-X', '--cleanup', dest='clean', default=False, action='store_true',
        help='Removes files from the Tape Manager\'s output directory (default: off)')
    cmdopts = cmdline.parse_args()

    # Set up the running environment for this script
    if not cmdopts.envfile:
        cmdopts.envfile = [ f"{gen_config_path()}/{DEFAULT_ENVFILE}" ]
    setenv_marchive(cmdopts.envfile[0], cmdopts.debug)

    # Set up logging
    setup_log(cmdopts,procname)

    # Read the Tape Manager configuration
    try:
        if cmdopts.tmconfig:                                          # use specified config file
            configfile = cmdopts.tmconfig[0]
        else:                                                         # get value from envronment variable
            configfile = os.getenv(TMCONFIG)
            if not configfile:
                raise IOError(f"{TMCONFIG} is not set. " +
                    "Cannot find the Tape Manager configuration. Exiting...")

        logger.info("Reading Tape Manager configuration from: %s", configfile)
        with open(configfile, 'rb') as conffh:
            config = tomllib.load(conffh)
    except IOError as e:
        logger.critical(e)
        sys.exit(42)
    tmdirmaps = setup_dirmaps(config)                                 # create maps needed to process object data/clean job files

    # Verify task argument before creating directory maps
    try:
        taskverified = False
        for t in config['tasks']:
            taskverified = cmdopts.task == t['name']
            if taskverified:
                looptime = get_timeout(t['timeout'])                  # set the looptime, based on the given task
                logger.info("Loop Wait Time: %d seconds (from [%s])",
                    looptime, cmdopts.task)
                break
        if not taskverified:
            raise NameError(f"Task value [{cmdopts.task}] is invalid. Exiting ...")
    except NameError as e:
        logger.critical(e)
        sys.exit(99)

    # Verify the Cleanup argument
    if cmdopts.clean:
        if cmdopts.infile[0] == '/dev/stdin' and not cmdopts.gencmd:  # No known object data to process
            if cmdopts.jobtag:
                cmdopts.infile = None
                logger.info("No object data specified to process. "+
                    "Will clean up Task Manager job files that are "+
                    "tagged with [%s]", cmdopts.jobtag[0])
            else:                                                     # have no way to determine what to clean up
                logger.critical("Cleanup ONLY specifed with no job tag "+
                    "(-X without -j <tag>). Exiting ...")
                sys.exit(99)
        else:
            if cmdopts.task == 'read':                                # Cannot process READ objects and then clean up immediately after
                logger.critical("Clean up of READ jobs may occur before "+
                    "Tape Manager can return data. -X option not allowed "+
                    "for this READ task! Exiting ...")
                sys.exit(99)

            if not cmdopts.jobtag:
                logger.warning("Cleanup specifed with no job tag. Only "+
                    "jobs generated from processing this object "+
                    "data will be cleaned up.")

    # Set up any input stream, if specified by the command options
    # Any generating commands takes presidence over any input files
    # that may inadvertently be specified (including /dev/stdin)
    if cmdopts.gencmd:
        logger.info("Reading from Command: %s", " ".join(cmdopts.gencmd))
        try:
            iproc = subprocess.Popen(cmdopts.gencmd, stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE, env=os.environ.copy())
            ihandle = io.TextIOWrapper(iproc.stdout, encoding="utf-8")
            isrcname = Path(cmdopts.gencmd[0]).name
        except OSError as e:
            logger.critical("Failed to start generating command: %s", e)
            sys.exit(42)
    elif cmdopts.infile:
        ihandle = open(cmdopts.infile[0], 'r', encoding="utf-8")
        isrcname = cmdopts.infile[0]

    # Process any object output data and Submit Tape Manager jobs
    if ihandle:
        logger.info("Processing lines from: %s", isrcname)

        # Generate job file prefix
        jobprefix = procname
        if cmdopts.gencmd:                                            # if generating command is used, then use that as the prefix
            jobprefix = f"{isrcname}_{iproc.pid}"
        if cmdopts.jobtag:                                            # add job tag, if specified
            jobprefix += f"_{cmdopts.jobtag[0]}"

        # Loop to process Object Output entries
        jobname = ""                                                  # initialize job name
        jobcnt = 0                                                    # initialize job count
        linecnt = 0                                                   # initialize line count

        for line in ihandle:
            if not linecnt:                                           # time to start using a new job number
                jobname = f"{jobprefix}.{jobcnt}"
                curtime = datetime.now()
                logger.info("Job %s started at %s (since epoch: %d)",
                    jobname, curtime, curtime.timestamp())

            process_object_line(line, cmdopts.task, jobname, tmdirmaps, ftab)
            linecnt += 1

            if not linecnt%maxjoblines:
                curtime = datetime.now()
                logger.info("Job %s ended at %s (since epoch: %d) "+
                    "Entries processed: %d", jobname, curtime, 
                    curtime.timestamp(), linecnt)
                jobcnt += 1
                linecnt = 0                                           # starting a new job ...

        curtime = datetime.now()
        logger.info("Job %s ended at %s (since epoch: %d) Entries processed: %d "+
            "Files created: %d", jobname, curtime, curtime.timestamp(), linecnt,
            len(ftab))

        # Close the input stream handle (and generating process, if needed)
        ihandle.close()
        if iproc:
            iproc.wait()                                              # make sure generating command is done
            if iproc.returncode:
                logger.warning("Command %s completed with return code: %d",
                    isrcname, iproc.returncode)

        # Submit job files to Tape Manager
        errkeys = []                                                  # list of keys that may be populated with submission errors
        for k, entry in ftab.items():
            if not submit_jobfile(entry):
                logger.error("Failed to submit job [%s] to tape manager!", k)
                errorhappened = True
                errkeys.append(k)
            else:
                logger.debug("Adding [%s] to watch list", k)
        if errkeys:                                                   # remove any failed submissions from file table
            for k in errkeys:
                entry = ftab.pop(k)
                errfile = entry[GENKEY]
                if errfile.exists():
                    logger.info("Removing job file %s after failed submission "+
                        "to tape manager.", errfile)        
                    try:
                        errfile.unlink()
                    except OSError as e:
                        logger.error("Problems deleting %s after failed "+
                            "job submission: %s", errfile, e)

        logger.info("Submitting %d job files from job submission [%s]...",
            len(ftab), jobprefix)

        # Now wait to see what the status of the job files is.
        # This is done by testing the existence of the file in either
        # the Tape Manger's SUCCESS or FAILURE subtrees
        while ftab:
            donekeys = []                                             # list of keys to remove from the file table

            time.sleep(looptime)                                      # give the tape manger time to so something ...
            for k,entry in ftab.items():
                if entry[SUCCESSKEY].exists():
                    logger.info("Job [%s] was Successful!", k)
                    donekeys.append(k)
                elif entry[FAILKEY].exists():
                    logger.error("Job [%s] Failed!",k)
                    errorhappened = True
                    donekeys.append(k)

            if donekeys:                                              # remove completed job files from file table
                for k in donekeys:
                    e = ftab.pop(k)
                    if cmdopts.clean:                                 # if cleaning up ouput files, then keep track of them
                        cleanupfiles.append(e)

            logger.debug("%d job files left", len(ftab))

    # Do job cleanup, if specified
    if cmdopts.clean:
        fcnt = 0                                                      # counter to keep track of how many files were removed
        if cleanupfiles:
            logger.info("Cleaning up %d job files...", len(cleanupfiles))
            for entry in cleanupfiles:                                # entries from the file table
                donefile = None

                if entry[SUCCESSKEY].exists():
                    donefile = entry[SUCCESSKEY]
                elif entry[FAILKEY].exists():
                    donefile = entry[FAILKEY]
                else:
                    logger.warning("No job file for [%s] to delete!",
                        entry[SUCCESSKEY].name)
                    continue

                try:
                    donefile.unlink()
                    fcnt +=1
                except OSError as e:
                    logger.error("Problems deleting %s: %s", donefile, e)
        elif cmdopts.jobtag:
            outroot = Path(tmdirmaps[SUCCESSKEY]).parent
            jglob = f"*_{cmdopts.jobtag[0]}*.req"                     # matches job files with tag

            logger.info("Cleaning up job files in %s, based on [%s]", outroot, jglob)
            for f in outroot.rglob(jglob):
                try:
                    f.unlink()
                    fcnt+=1
                except OSError as e:
                    logger.error("Problems deleting %s: %s", donefile, e)
        else:
            logger.error("No way to determine what job files needed to be cleaned up!")
            errorhappened = True
        logger.info("Number of job files removed: %d", fcnt)

    if errorhappened:
        sys.exit(1)
    sys.exit(0)
